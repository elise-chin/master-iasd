{"cells":[{"cell_type":"markdown","metadata":{"id":"GqDAHSx_XFh9"},"source":["# MDP - Résolution par programmation dynamique (Value Iteration & Policy Iteration)\n","\n","*Version 1 - Elise Chin, December 2021*\n","\n","1. [Value Iteration](#sec1)\n","2. [Policy Iteration](#sec2)\n","\n","Supposons que le modèle de transition soit connu. On souhaite trouver une politique optimale pour un problème donné formulé comme un processus décisionnel de Markov (MDP). L'idée est d'utiliser l'expression de droite des équations de Bellman pour converger vers la fonction de valeur optimale pour les états $v_*$ ou la fonction de valeurs optimale pour les paires état-actions $q_*$ grâce à des algorithmes itératifs. On en déduit ensuite la politique optimale :\n","\n","$$\n","\\pi_*(s) = \\underset{a}{\\operatorname{argmax}} q_*(s,a).\n","$$\n"]},{"cell_type":"markdown","metadata":{"id":"BeCbCndGXPr_"},"source":["On va utiliser l'exemple du monde grille simple. \n","\n","![Grid World](https://www.lamsade.dauphine.fr/~airiau/Teaching/M2-IASDapp-RL/gridworld.png)\n","\n","\n","\n","On va numéroter les états comme suit :\n","\n","| 7 | 8 | 9 | 10 |\n","|---|---|----|---|\n","| **4** |  - | **5** | **6**  |\n","| **0** | **1** | **2** | **3**  |\n","\n","Les états finaux sont donc les états 6 et 10.\n","\n","On a 4 actions disponibles, on les encode de la façon suivante :\n","* $\\uparrow$: 0 \n","* $\\leftarrow$ : 1\n","* $\\downarrow$: 2\n","* $\\rightarrow$ : 3\n","\n","Ci-dessous, on a entré la matrice de transition $T$ et la matrice de récompense $R$. Ainsi $T[s_1,a,s_2]$ donne la probabilité d'atteindre l'état $s_2$ en ayant pris l'action $a$ dans l'état $s_1$ et $R[s,a]$ donne la récompense immédiate reçue après avoir pris l'action $a$ dans l'état $s$.\n","\n","Vous pouvez facilement changer la pénalité pour avancer d'une case en changeant la valeur de la variable `penalty` ci-dessous.\n","\n","Ce n'est peut-être pas la manière la plus élégante, mais cela suffira pour l'exercice !"]},{"cell_type":"markdown","metadata":{"id":"HqhuJ-ofCHNQ"},"source":["On connaît le modèle de transition \n","\n","$$\n","p(s' | s,a) = \\mathbb{P}[S_{t+1} = s' | S_t = s, A_t = a]\n","$$\n","\n","défini par la matrice $T$ et le modèle de récompense \n","\n","$$\n","r(s,a) = \\mathbb{E}[R_{t+1} | S_t = s, A_t = a]\n","$$\n","\n","défini par la matrice $R$."]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":309,"status":"ok","timestamp":1640382343195,"user":{"displayName":"Elise Chin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg3r39dWxuuOmIlfnHXG7UGWZFeioC7aAeEVwF6=s64","userId":"02486712746794505423"},"user_tz":-60},"id":"x1GCwZzEG3cJ"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":266,"status":"ok","timestamp":1640382343752,"user":{"displayName":"Elise Chin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg3r39dWxuuOmIlfnHXG7UGWZFeioC7aAeEVwF6=s64","userId":"02486712746794505423"},"user_tz":-60},"id":"AGGujRrVXEe3"},"outputs":[],"source":["l = 0.8\n","s = 0.1\n","v_win = 1\n","v_lose = -1\n","\n","# Transition Matrix\n","T = np.zeros((11, 4, 11))\n","\n","# UP\n","T[0,0,:]=[s, s, 0, 0, l, 0, 0, 0, 0, 0, 0 ] \n","T[1,0,:]=[s, l, s, 0, 0, 0, 0, 0, 0, 0, 0 ]\n","T[2,0,:]=[0, s, 0, s, 0, l, 0, 0, 0, 0, 0 ]\n","T[3,0,:]=[0, 0, s, s, 0, 0, l, 0, 0, 0, 0 ]\n","T[4,0,:]=[0, 0, 0, 0, 2*s, 0, 0, l, 0, 0, 0 ]\n","T[5,0,:]=[0, 0, 0, 0, 0, s, s, 0, 0, l, 0 ]\n","T[6,0,:]=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 ]\n","T[7,0,:]=[0, 0, 0, 0, 0, 0, 0, s+l, s, 0, 0 ]\n","T[8,0,:]=[0, 0, 0, 0, 0, 0, 0, s, l, s, 0 ]\n","T[9,0,:]=[0, 0, 0, 0, 0, 0, 0, 0, s, l, s ]\n","T[10,0,:]=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0,0 ]\n","\n","# LEFT\n","T[0,1,:]=[s+l, 0, 0, 0, s, 0, 0, 0, 0, 0, 0 ] \n","T[1,1,:]=[l, 2*s, 0, 0, 0, 0, 0, 0, 0, 0, 0 ]\n","T[2,1,:]=[0, l, s, 0, 0, s, 0, 0, 0, 0, 0 ]\n","T[3,1,:]=[0, 0, l, s, 0, 0, s, 0, 0, 0, 0 ]\n","T[4,1,:]=[s, 0, 0, 0, l, 0, 0, s, 0, 0, 0 ]\n","T[5,1,:]=[0, 0, s, 0, 0, l, 0, 0, 0, s, 0 ]\n","T[6,1,:]=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 ]\n","T[7,1,:]=[0, 0, 0, 0, s, 0, 0, s+l, 0, 0, 0 ]\n","T[8,1,:]=[0, 0, 0, 0, 0, 0, 0, l, 2*s, 0, 0 ]\n","T[9,1,:]=[0, 0, 0, 0, 0, s, 0, 0, l, s, 0 ]\n","T[10,1,:]=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0,0 ]\n","\n","# DOWN\n","T[0,2,:]=[s+l, s, 0, 0, 0, 0, 0, 0, 0, 0, 0 ] \n","T[1,2,:]=[s, l, s, 0, 0, 0, 0, 0, 0, 0, 0 ]\n","T[2,2,:]=[0, s, l, s, 0, 0, 0, 0, 0, 0, 0 ]\n","T[3,2,:]=[0, 0, s, l+s, 0, 0, 0, 0, 0, 0, 0 ]\n","T[4,2,:]=[l, 0, 0, 0, 2*s, 0, 0, 0, 0, 0, 0 ]\n","T[5,2,:]=[0, 0, l, 0, 0, s, s, 0, 0, 0, 0 ]\n","T[6,2,:]=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 ]\n","T[7,2,:]=[0, 0, 0, 0, l, 0, 0, s, s, 0, 0 ]\n","T[8,2,:]=[0, 0, 0, 0, 0, 0, 0, s, l, s, 0 ]\n","T[9,2,:]=[0, 0, 0, 0, 0, 0, 0, 0, s, l, s ]\n","T[10,2,:]=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0,0 ]\n","\n","# RIGHT\n","T[0,3,:]=[s, l, 0, 0, s, 0, 0, 0, 0, 0, 0 ] \n","T[1,3,:]=[0, 2*s, l, 0, 0, 0, 0, 0, 0, 0, 0 ]\n","T[2,3,:]=[0, 0, s, l, 0, s, 0, 0, 0, 0, 0 ]\n","T[3,3,:]=[0, 0, 0, s+l, 0, 0, s, 0, 0, 0, 0 ]\n","T[4,3,:]=[s, 0, 0, 0, l, 0, 0, s, 0, 0, 0 ]\n","T[5,3,:]=[0, 0, s, 0, 0, 0, l, 0, 0, s, 0 ]\n","T[6,3,:]=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 ]\n","T[7,3,:]=[0, 0, 0, 0, s, 0, 0, s, l, 0, 0 ]\n","T[8,3,:]=[0, 0, 0, 0, 0, 0, 0, 0, 2*s, l, 0 ]\n","T[9,3,:]=[0, 0, 0, 0, 0, s, 0, 0, 0, s, l ]\n","T[10,3,:]=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0,0 ]\n","\n","\n","# Reward matrix\n","penalty = 0.00\n","R = penalty * np.ones((11,4))\n","R[10,:] = np.ones(4) * v_win\n","R[6,:] = np.ones(4) * v_lose"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1640382343752,"user":{"displayName":"Elise Chin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg3r39dWxuuOmIlfnHXG7UGWZFeioC7aAeEVwF6=s64","userId":"02486712746794505423"},"user_tz":-60},"id":"CT4-onUnG3cR"},"outputs":[],"source":["class Environment():\n","    \n","    def __init__(self, observation_space, action_space, transition_matrix, reward_matrix):\n","        self.observation_space = observation_space\n","        self.action_space = action_space\n","        self.n_states = len(observation_space) # Number of actions\n","        self.n_actions = len(action_space) # Number of spaces\n","        self.T = transition_matrix \n","        self.R = reward_matrix"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1640382343753,"user":{"displayName":"Elise Chin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg3r39dWxuuOmIlfnHXG7UGWZFeioC7aAeEVwF6=s64","userId":"02486712746794505423"},"user_tz":-60},"id":"MSq8BXF6G3cU"},"outputs":[],"source":["observation_space = list(range(11))\n","action_space = list(range(4))\n","env = Environment(observation_space, action_space, T, R)"]},{"cell_type":"markdown","metadata":{"id":"J-PfAVpFC0yu"},"source":["## <a name=\"sec1\">1. Value Iteration</a>\n","\n","L'algorithme d'itération sur les valeurs permet de trouver la fonction de valeur optimale $v_*$ par une méthode itérative. Il est basé sur les équations d'optimalité de Bellman.\n","\n","On sait que \n","$$\n","v_*(s) = \\underset{a \\in \\mathcal{A}}{\\operatorname{max}} q_*(s,a) \n","$$\n","et que \n","$$\n","q_*(s,a) = r(s,a) + \\gamma \\sum_{s' \\in \\mathcal{S}} p(s'|s,a) v_*(s')\n","$$\n","\n","Donc \n","$$\n","v_*(s) = \\underset{a \\in \\mathcal{A}}{\\operatorname{max}} r(s,a) + \\gamma \\sum_{s' \\in \\mathcal{S}} p(s'|s,a) v_*(s')\n","$$\n","\n","La solution de l'équation de Bellman optimale est l'unique point fixe de l'opérateur de Bellman $\\tau$, i.e. la suite $v_{k+1} = \\tau v_k$ converge vers $v_*$. Pour trouver la solution, on peut donc appliquer itérativement l'opérateur pour converger vers l'optimal : \n","\n","$$\n","v_{k+1}(s) = \\underset{a \\in \\mathcal{A}}{\\operatorname{max}} r(s,a) + \\gamma \\sum_{s' \\in \\mathcal{S}} p(s'|s,a) v_k(s')\n","$$"]},{"cell_type":"markdown","metadata":{"id":"yv5FRRwIJOnr"},"source":["La fonction `value_iteration()` prend en paramètres :\n","- `env` l'environnement décrit par la matrice de transition $T$ et la matrice de récompense $R$\n","- `gamma` le taux d'escompte (i.e. la valeur à l'instant $t$ d'obtenir une unité de récompense à l'instant $t+1$)\n","- `max_iter` le nombre d'itérations maximal\n","- `epsilon` le paramètre pour le test d'arrêt\n","\n","La méthode retourne le vecteur $v: S \\rightarrow {\\mathbb R}$ qui associe à chaque état la valeur optimale de cet état.\n","\n","Pour la mise à jour des valeurs de $v$, on utilisera une fonction intermédiaire `compute_action_value()` qui permet de calculer $q(s,a)$ étant donné un état $s$, une action $a$ et l'estimation courante de $v$."]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1640382343753,"user":{"displayName":"Elise Chin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg3r39dWxuuOmIlfnHXG7UGWZFeioC7aAeEVwF6=s64","userId":"02486712746794505423"},"user_tz":-60},"id":"iEgyhjrLG3cY"},"outputs":[],"source":["def compute_action_value(env, gamma, s, a, v):\n","    '''Compute q_pi(s,a) given v_pi(s)'''\n","\n","    action_value = env.R[s,a] + gamma * sum([env.T[s,a,next_s]*v[next_s] for next_s in range(env.n_states)])\n","    return action_value"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1640382343754,"user":{"displayName":"Elise Chin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg3r39dWxuuOmIlfnHXG7UGWZFeioC7aAeEVwF6=s64","userId":"02486712746794505423"},"user_tz":-60},"id":"J_W8AJn_G3cZ"},"outputs":[],"source":["def value_iteration(env, gamma, max_iter=100, epsilon=1e-2):\n","    \n","    v = np.zeros(env.n_states)\n","    \n","    for i in range(max_iter):\n","        delta = 0\n","\n","        # For each state...\n","        for s in range(env.n_states):\n","\n","            # Get the current estimation for state s, to compute delta\n","            vs = v[s]\n","            \n","            # Compute action value function with current estimate of v\n","            action_values = np.array([compute_action_value(env, gamma, s, a, v) for a in range(env.n_actions)])\n","            \n","            # Update v for state s\n","            v[s] = np.max(action_values)\n","            \n","            # Update the biggest difference\n","            delta = np.max([delta, np.abs(vs-v[s])])\n","\n","        # Convergence test, until delta < epsilon\n","        if (delta < epsilon):\n","            print(f'Break after {i} iterations.')\n","            break\n","            \n","    return v    "]},{"cell_type":"markdown","metadata":{"id":"RslehqpNJisa"},"source":["La fonction $printV$ ci-dessous affichera les valeurs de $v$ pour le problème du gridworld."]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":205,"status":"ok","timestamp":1640382343953,"user":{"displayName":"Elise Chin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg3r39dWxuuOmIlfnHXG7UGWZFeioC7aAeEVwF6=s64","userId":"02486712746794505423"},"user_tz":-60},"id":"y2iqnIKhlg2k"},"outputs":[],"source":["def printV(v):\n","    print('| {:03.2f} | {:03.2f} | {:03.2f} | {:03.2f} |'.format(v[7], v[8], v[9], v[10]))\n","    print('| {:03.2f} | ---- | {:03.2f} | {:03.1f} |'.format(v[4], v[5], v[6]))\n","    print('| {:03.2f} | {:03.2f} | {:03.2f} | {:03.2f} |'.format(v[0], v[1], v[2], v[3]))"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1640382343954,"user":{"displayName":"Elise Chin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg3r39dWxuuOmIlfnHXG7UGWZFeioC7aAeEVwF6=s64","userId":"02486712746794505423"},"user_tz":-60},"id":"ai_RjaGylVnM","outputId":"772da522-d777-48fa-b468-eec94c72c390"},"outputs":[{"name":"stdout","output_type":"stream","text":["| 0.00 | 0.00 | 0.00 | 1.00 |\n","| 0.00 | ---- | 0.00 | -1.0 |\n","| 0.00 | 0.00 | 0.00 | 0.00 |\n","| 0.00 | 0.00 | 0.72 | 1.00 |\n","| 0.00 | ---- | 0.00 | -1.0 |\n","| 0.00 | 0.00 | 0.00 | 0.00 |\n","| 0.00 | 0.52 | 0.82 | 1.00 |\n","| 0.00 | ---- | 0.43 | -1.0 |\n","| 0.00 | 0.00 | 0.00 | 0.00 |\n","| 0.37 | 0.69 | 0.84 | 1.00 |\n","| 0.00 | ---- | 0.54 | -1.0 |\n","| 0.00 | 0.00 | 0.31 | 0.13 |\n","| 0.55 | 0.73 | 0.85 | 1.00 |\n","| 0.27 | ---- | 0.57 | -1.0 |\n","| 0.00 | 0.22 | 0.42 | 0.23 |\n","| 0.62 | 0.74 | 0.85 | 1.00 |\n","| 0.45 | ---- | 0.57 | -1.0 |\n","| 0.21 | 0.34 | 0.46 | 0.26 |\n","| 0.64 | 0.74 | 0.85 | 1.00 |\n","| 0.52 | ---- | 0.57 | -1.0 |\n","| 0.37 | 0.39 | 0.47 | 0.27 |\n","| 0.64 | 0.74 | 0.85 | 1.00 |\n","| 0.55 | ---- | 0.57 | -1.0 |\n","| 0.45 | 0.41 | 0.47 | 0.27 |\n","| 0.64 | 0.74 | 0.85 | 1.00 |\n","| 0.56 | ---- | 0.57 | -1.0 |\n","| 0.47 | 0.42 | 0.47 | 0.28 |\n","| 0.64 | 0.74 | 0.85 | 1.00 |\n","| 0.56 | ---- | 0.57 | -1.0 |\n","| 0.48 | 0.42 | 0.47 | 0.28 |\n","| 0.64 | 0.74 | 0.85 | 1.00 |\n","| 0.57 | ---- | 0.57 | -1.0 |\n","| 0.49 | 0.43 | 0.48 | 0.28 |\n","Break after 10 iterations.\n","| 0.64 | 0.74 | 0.85 | 1.00 |\n","| 0.57 | ---- | 0.57 | -1.0 |\n","| 0.49 | 0.43 | 0.48 | 0.28 |\n"]}],"source":["v = value_iteration(env, gamma=0.9, max_iter=100, epsilon=1e-2)\n","printV(v)"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1640382343954,"user":{"displayName":"Elise Chin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg3r39dWxuuOmIlfnHXG7UGWZFeioC7aAeEVwF6=s64","userId":"02486712746794505423"},"user_tz":-60},"id":"jvibNWnFzAQO"},"outputs":[],"source":["# Plot the best policy given the value function v:\n","# i.e. plot the best action for each state given the value function v.\n","\n","def plotBestPolicy(v, gamma):\n","    bestV = np.zeros(11)\n","    bestA = np.zeros(11)\n","    fig, ax = plt.subplots()\n","    \n","    # Policy extraction\n","    for s1 in range(11):\n","        val = []\n","        for a in range(4):\n","            va = 0\n","        for s2 in range(11):\n","            va += T[s1,a,s2] * v[s2]\n","        val = val + [R[s1,a] + gamma*va]\n","        bestV[s1] = np.max(val)\n","        bestA[s1] = np.argmax(val)\n","\n","        matV= np.array( [[bestV[7], bestV[8], bestV[9], bestV[10]],\n","                        [bestV[4],   -1 , bestV[5], bestV[6]],\n","                        [bestV[0], bestV[1], bestV[2], bestV[3]]]\n","                        )\n","        matA = np.array([\n","                        [bestA[7], bestA[8], bestA[9], -1],\n","                        [bestA[4],   -1 , bestA[5], -1],\n","                        [bestA[0], bestA[1], bestA[2], bestA[3]]])\n","\n","        im = ax.imshow(matV)\n","\n","    for i in range(matV.shape[0]):\n","        for j in range(matV.shape[1]):\n","            if matA[i][j]==-1:\n","                arrow = ''\n","            elif matA[i, j] == 0:\n","                arrow = '^'\n","            elif matA[i, j] == 1:\n","                arrow = '<'\n","            elif matA[i, j] == 2:\n","                arrow = 'v'\n","            elif matA[i, j] == 3:\n","                arrow = '>'\n","            text = ax.text(j, i, arrow, ha = \"center\", va = \"center\",\n","                            color = \"black\")\n","                \n","    cbar = ax.figure.colorbar(im, ax = ax)\n","        \n","    fig.tight_layout()\n","    plt.show() "]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":295},"executionInfo":{"elapsed":805,"status":"ok","timestamp":1640382344756,"user":{"displayName":"Elise Chin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg3r39dWxuuOmIlfnHXG7UGWZFeioC7aAeEVwF6=s64","userId":"02486712746794505423"},"user_tz":-60},"id":"4AMDenr44UCt","outputId":"f9da9421-c1f3-4de3-d121-587220407672"},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["plotBestPolicy(v, 0.9)"]},{"cell_type":"markdown","metadata":{"id":"j6Gh1rWu6SLI"},"source":["## <a name=\"sec2\">2. Policy Iteration</a>\n","\n","Une autre stratégie pour calculer $v_*$ et $q_*$ est de partir d'une politique arbitraire $\\pi$ et de l'améliorer : c'est l'algorithme d'itération sur les politiques. Il se décompose en deux phases qu'on alterne jusqu'à ce qu'on converge vers une politique qui sera la politique optimale :\n","1. Evaluation de la politique\n","2. Amélioration de la politique\n","\n","\n","__Evaluation de la politique__\n","\n","Etant donné $\\pi$, on cherche à calculer $v_{\\pi}(s)$ pour tout $s \\in \\mathcal{S}$. L'idée est de partir d'une estimation initiale $v_0$ (e.g. $v_0(s) = 0 \\space \\forall s$) puis de calculer de nouvelles estimations en utilisant l'expression de droite de l'équation de Bellman pour les valeurs d'états.\n","Le pseudo-code est le suivant :\n","\n","1. Initialize $v_{old}$ (e.g. $v_{old}(s) = 0 \\space \\forall s$)\n","2. $\\forall s \\in \\mathcal{S}$\n","$$\n","v_{new}(s) = \\sum_{a \\in \\mathcal{A}} \\pi(a|s) \\left(r(s,a) + \\gamma \\sum_{s' \\in \\mathcal{S}} p(s'|s,a)v_{\\pi}(s') \\right)\n","$$\n","3. If |$v_{old}(s) - v_{new}(s)$| < tol $\\forall s$, output $v_{new}$ and stop\n","4. Otherwise, let $v_{old} ← v_{new}$ and step 2\n","\n","__Amélioration de la politique__\n","\n","Une fois $v_{\\pi}$ évaluée, on peut calculer $\n","q_{\\pi}(s,a) = r(s,a) + \\gamma \\sum_{s' \\in \\mathcal{S}} p(s'|s,a) v_{\\pi}(s')$. Puis à partir de $q_{\\pi}$, améliorer la politique en se comportant de manière \"gloutonne\", c'est-à-dire :\n","$$\n","\\pi'(s) = \\underset{a}{\\operatorname{argmax}} q_{\\pi}(s,a).\n","$$\n","\n","L'algorithme d'itération sur les politiques alterne entre ces deux étapes jusqu'à ce qu'aucune amélioration n'a été trouvée. La dernière fonction de valeur évaluée est donc $v_*$ et à partir de cette fonction, on peut en déduire $q_*$ puis $\\pi_*$. "]},{"cell_type":"markdown","metadata":{"id":"C_VnZrkBR1jF"},"source":["### 2.1 Policy evaluation"]},{"cell_type":"markdown","metadata":{"id":"NoYAAZzBTpTD"},"source":["Implémentons une fonction pour évaluer une politique. \n","\n","Pour cela, nous allons tout d'abord créer une fonction `Bellman_RHS_all()` qui calcule l'expression de droite de l'équation de Bellman pour chaque état, en utilisant la fonction intermédiaire `Bellman_RHS()` qui calcule la valeur pour un état donné."]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1640382344756,"user":{"displayName":"Elise Chin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg3r39dWxuuOmIlfnHXG7UGWZFeioC7aAeEVwF6=s64","userId":"02486712746794505423"},"user_tz":-60},"id":"wz06Xp03AVxS"},"outputs":[],"source":["def Bellman_RHS(env, pi, gamma, s, v):\n","    '''Compute the right-hand side of the Bellman equation'''\n","\n","    state_value = 0\n","    for a in range(env.n_actions):\n","        state_value += pi[s,a] * compute_action_value(env, gamma, s, a, v)\n","    return state_value\n","\n","def Bellman_RHS_all(env, pi, gamma, v0):\n","    '''Given a value function, computes the right-hand side \n","    of the Bellman equation for all states'''\n","\n","    # v0 is the given value function\n","    # v will be the right-hand side of the Bellman equation\n","    # If v0 is indeed the value function, then we should get v = v0.\n","    \n","    v = np.zeros(env.n_states)\n","    for s in range(env.n_states):\n","        v[s] = Bellman_RHS(env, pi, gamma, s, v0)\n","    return v"]},{"cell_type":"markdown","metadata":{"id":"ncp_rkNqUVFO"},"source":["La fonction `policy_evaluation()` permet d'évaluer une politique. On implémente le pseudo-code présenté ci-dessus."]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1640382344757,"user":{"displayName":"Elise Chin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg3r39dWxuuOmIlfnHXG7UGWZFeioC7aAeEVwF6=s64","userId":"02486712746794505423"},"user_tz":-60},"id":"vrZdu5hqG3ck"},"outputs":[],"source":["def policy_evaluation(env, pi, gamma, v0, max_iter=100, epsilon=1e-2):\n","    \n","    # Initial guess\n","    v_old = v0\n","    \n","    for _ in range(max_iter):\n","        v_new = Bellman_RHS_all(env, pi, gamma, v_old)\n","        \n","        if np.max(np.abs(v_new - v_old)) < epsilon:\n","            break\n","        \n","        v_old = v_new\n","        \n","    return v_new"]},{"cell_type":"markdown","metadata":{"id":"svvJ7UazUrhI"},"source":["### 2.2 Policy improvement"]},{"cell_type":"markdown","metadata":{"id":"UgW2OnRJG3ci"},"source":["`policy_improvement()` retourne `pi` qui encode une politique gloutonne selon `v` et `q` calculée à partir de `v`. On a `pi[s][a]`  $= \\pi(a|s)$."]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1640382344757,"user":{"displayName":"Elise Chin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg3r39dWxuuOmIlfnHXG7UGWZFeioC7aAeEVwF6=s64","userId":"02486712746794505423"},"user_tz":-60},"id":"2zl-gkquG3cj"},"outputs":[],"source":["def policy_improvement(env, gamma, v):\n","    \n","    # The new policy will be a_probs\n","    # We start by setting all probabilities to 0\n","    # Then when we have found the greedy action in a state, \n","    # we change the probability for that action to 1.0.\n","    \n","    pi = np.zeros((env.n_states, env.n_actions))\n","    q = np.zeros((env.n_states, env.n_actions))\n","\n","    for s in range(env.n_states):\n","\n","        # Compute action value for all actions\n","        for a in range(env.n_actions):\n","            q[s,a] = compute_action_value(env, gamma, s, a, v)\n","            \n","        a_max = np.argmax(q[s]) # A greedy action\n","        pi[s][a_max] = 1.0 # Always choose the greedy action\n","        \n","    return pi, q"]},{"cell_type":"markdown","metadata":{"id":"M6h_DxUSVJTk"},"source":["### 2.3 Policy iteration "]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1640382344758,"user":{"displayName":"Elise Chin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg3r39dWxuuOmIlfnHXG7UGWZFeioC7aAeEVwF6=s64","userId":"02486712746794505423"},"user_tz":-60},"id":"G9X0InrKG3cl"},"outputs":[],"source":["def policy_iteration(env, gamma, max_iter, epsilon=1e-2):\n","    \n","    # Initialisation\n","    v = np.zeros(env.n_states)\n","    \n","    for i in range(max_iter):\n","        v_old = v\n","        \n","        # Policy improvement (i.e. act greedy w.r.t v)\n","        pi, q = policy_improvement(env, gamma, v_old)\n","        \n","        # Policy evaluation\n","        v = policy_evaluation(env, pi, gamma, v_old)\n","        \n","        delta = np.max(np.abs(v_old - v))\n","        if delta < epsilon:\n","            print(f'Break after {i} iterations.')\n","            break\n","    \n","    return v, q, pi"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1640382344758,"user":{"displayName":"Elise Chin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg3r39dWxuuOmIlfnHXG7UGWZFeioC7aAeEVwF6=s64","userId":"02486712746794505423"},"user_tz":-60},"id":"7r3CXAgxG3cl","outputId":"7f1b99a2-a499-4a88-f93a-bfd214e351d2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Break after 2 iterations.\n"]}],"source":["v_star, q_star, pi_star = policy_iteration(env, gamma=0.9, max_iter=100, epsilon=1e-2)"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1640382344759,"user":{"displayName":"Elise Chin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg3r39dWxuuOmIlfnHXG7UGWZFeioC7aAeEVwF6=s64","userId":"02486712746794505423"},"user_tz":-60},"id":"5omADZk2G3cm","outputId":"f28861e3-f11d-4aa8-8304-246534324ceb"},"outputs":[{"name":"stdout","output_type":"stream","text":["| 0.64 | 0.74 | 0.85 | 1.00 |\n","| 0.57 | ---- | 0.57 | -1.0 |\n","| 0.49 | 0.42 | 0.47 | 0.28 |\n"]}],"source":["printV(v_star)"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":295},"executionInfo":{"elapsed":573,"status":"ok","timestamp":1640382345324,"user":{"displayName":"Elise Chin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg3r39dWxuuOmIlfnHXG7UGWZFeioC7aAeEVwF6=s64","userId":"02486712746794505423"},"user_tz":-60},"id":"Ou4GZrCPG3cn","outputId":"f7d4d5e1-e11b-44b8-cdc7-43bfb4090429"},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["plotBestPolicy(v_star, 0.9)"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"02_Value_iteration_Policy_iteration.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":0}
